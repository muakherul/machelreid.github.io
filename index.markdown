---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
author: Machel Reid 
title: Hi There! Name's Machel
description: Research Intern at the University of Tokyo working on natural language processing research
---

I'm a 16-year-old research intern at the University of Tokyo, working on NLP Research at [Matsuo Lab](https://weblab.t.u-tokyo.ac.jp/en/){:target="_blank"} advised by Professor [Yutaka Matsuo](http://ymatsuo.com/){:target="_blank"}. Here, I am currently working on ways to learn representations of edits and ways of editing documents, but I am also interested in/working on definitions, translation, and anything to do with deep generative models (like VAEs). 

I'm also an associate member at the [Masason Foundation](https://masason-foundation.org/en/){:target="_blank"}.

Previously, I worked on a project for automation of helplines during natural disasters, during my internship at Numada Lab, The University of Tokyo,  and even further back, I was part of the team that won the Rakuten Hackathon in 2018, being the youngest participant at age 14.

Before entering the field of machine learning and computational linguistics, I worked for the Thomson Reuters Foundation as a researcher and participated in the conduction of two annual studies, and have this article ([https://www.weforum.org/agenda/authors/machel-reid/](https://www.weforum.org/agenda/authors/machel-reid/){:target="_blank"}) published in the World Economic Forum.

## News
* I'm extremely grateful to be accepted as a 4th Generation Masason Foundation Scholar! - July 2020

* Our paper: [*Variational Inference for Learning Representations of Natural Language Edits*](https://arxiv.org/pdf/2004.09143.pdf){:target="_blank"} was accepted to the non-archival track of the [5th Workshop of Representation Learning for NLP](https://sites.google.com/view/repl4nlp2020/){:target="_blank"} at [ACL 2020](http://acl2020.org/){:target="_blank"} - May 2020

* Our paper: [*Combining Pretrained High Resource Embeddings and Subword Representations for Low-Resource Languages*](https://arxiv.org/pdf/2003.04419.pdf){:target="_blank"} was accepted to the AfricaNLP Workshop at [ICLR 2020](https://iclr.cc/){:target="_blank"} - March 2020


